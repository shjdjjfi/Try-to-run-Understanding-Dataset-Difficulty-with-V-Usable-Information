{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22766,"status":"ok","timestamp":1677757652237,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"T-IHR2zXWQLg","outputId":"5817df98-4e23-45b7-f2b7-d73a5f11e986"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439,"status":"ok","timestamp":1677757656735,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"TzsrtqNyW2tM","outputId":"0175cdea-7607-4b16-eb7d-d108dce74240"},"outputs":[{"output_type":"stream","name":"stdout","text":["'Colab Notebooks'   dataset_difficulty\t      nyarumul\n"," dataset\t    dataset_difficulty-main\n"]}],"source":["import os\n","os.chdir(\"/content/drive/My Drive\")\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677757659000,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"63Rj1LB9W5uc","outputId":"b290c5b9-b6ae-4781-d702-b900a173b63a"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'dataset_difficulty' already exists and is not an empty directory.\n","'Colab Notebooks'   dataset_difficulty\t      nyarumul\n"," dataset\t    dataset_difficulty-main\n"]}],"source":["!git clone https://github.com/kawine/dataset_difficulty.git\n","!ls"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5v7YGkdiXldk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677757686924,"user_tz":-480,"elapsed":2,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"}},"outputId":"d5ac7fc3-4257-4d7c-eb8d-daaa01af4a0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/dataset_difficulty\n"]}],"source":["%cd dataset_difficulty/"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":433,"status":"ok","timestamp":1677757714023,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"Hb2OKfjiXu_T","outputId":"e25d624c-b0d2-441b-ebd3-c3c76a8646f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["artefacts   finetune.sh  __pycache__\t   results.py\t\t   v_info.py\n","augment.py  plot.ipynb\t README.md\t   run_glue_no_trainer.py\n","data\t    PVI\t\t requirements.txt  setup.sh\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104193,"status":"ok","timestamp":1677757822770,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"n6yTCv8mX3Sb","outputId":"af43933c-ae64-41c1-ea9e-865dee7d4753"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting accelerate==0.3.0\n","  Downloading accelerate-0.3.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets==1.9.0\n","  Downloading datasets-1.9.0-py3-none-any.whl (262 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.3/262.3 KB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting matplotlib==3.3.4\n","  Downloading matplotlib-3.3.4-cp38-cp38-manylinux1_x86_64.whl (11.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pandas==1.1.5\n","  Downloading pandas-1.1.5-cp38-cp38-manylinux1_x86_64.whl (9.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy==1.5.4\n","  Downloading scipy-1.5.4-cp38-cp38-manylinux1_x86_64.whl (25.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting spacy==3.2.0\n","  Downloading spacy-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting spacytextblob==3.0.1\n","  Downloading spacytextblob-3.0.1-py3-none-any.whl (4.1 kB)\n","Collecting tokenizers==0.10.3\n","  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch==1.9.0\n","  Downloading torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.4/831.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tqdm==4.61.2\n","  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.9.1\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyaml>=20.4.0\n","  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets==1.9.0->-r requirements.txt (line 4)) (0.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.9.0->-r requirements.txt (line 4)) (2.25.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.9.0->-r requirements.txt (line 4)) (2023.1.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.9.0->-r requirements.txt (line 4)) (9.0.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets==1.9.0->-r requirements.txt (line 4)) (23.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 5)) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 5)) (0.11.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 5)) (8.4.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 5)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.3.4->-r requirements.txt (line 5)) (1.4.4)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas==1.1.5->-r requirements.txt (line 7)) (2022.7.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (3.1.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (2.0.8)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (1.0.9)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (2.4.5)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (1.0.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (3.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (2.0.7)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (0.10.1)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.1/671.1 KB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (3.0.8)\n","Collecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (0.7.9)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (0.10.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (57.4.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy==3.2.0->-r requirements.txt (line 9)) (3.3.0)\n","Requirement already satisfied: textblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.8/dist-packages (from spacytextblob==3.0.1->-r requirements.txt (line 10)) (0.15.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.9.0->-r requirements.txt (line 12)) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.9.1->-r requirements.txt (line 14)) (3.9.0)\n","Collecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.9.1->-r requirements.txt (line 14)) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.9.1->-r requirements.txt (line 14)) (2022.6.2)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy==3.2.0->-r requirements.txt (line 9)) (6.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.4->-r requirements.txt (line 5)) (1.15.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.9.0->-r requirements.txt (line 4)) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.9.0->-r requirements.txt (line 4)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.9.0->-r requirements.txt (line 4)) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.9.0->-r requirements.txt (line 4)) (2.10)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.8/dist-packages (from textblob<0.16.0,>=0.15.3->spacytextblob==3.0.1->-r requirements.txt (line 10)) (3.7)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.5.0,>=0.3.0->spacy==3.2.0->-r requirements.txt (line 9)) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy==3.2.0->-r requirements.txt (line 9)) (2.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.9.1->-r requirements.txt (line 14)) (1.2.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b209f11baa495cfd7dd18ac08bf0808fde2df5741adec4fab419803acb6ba90d\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, xxhash, typer, tqdm, torch, pydantic, pyaml, numpy, multiprocess, scipy, sacremoses, pandas, matplotlib, huggingface-hub, accelerate, transformers, thinc, datasets, spacy, spacytextblob\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.7.0\n","    Uninstalling typer-0.7.0:\n","      Successfully uninstalled typer-0.7.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.64.1\n","    Uninstalling tqdm-4.64.1:\n","      Successfully uninstalled tqdm-4.64.1\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.5\n","    Uninstalling pydantic-1.10.5:\n","      Successfully uninstalled pydantic-1.10.5\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.7.3\n","    Uninstalling scipy-1.7.3:\n","      Successfully uninstalled scipy-1.7.3\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.5.3\n","    Uninstalling matplotlib-3.5.3:\n","      Successfully uninstalled matplotlib-3.5.3\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 8.1.7\n","    Uninstalling thinc-8.1.7:\n","      Successfully uninstalled thinc-8.1.7\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.4.4\n","    Uninstalling spacy-3.4.4:\n","      Successfully uninstalled spacy-3.4.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.1.5 which is incompatible.\n","xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\n","torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n","tensorflow 2.11.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jaxlib 0.4.4+cuda11.cudnn82 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","jax 0.4.4 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\n","cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.3.0 datasets-1.9.0 huggingface-hub-0.0.12 matplotlib-3.3.4 multiprocess-0.70.14 numpy-1.19.5 pandas-1.1.5 pyaml-21.10.1 pydantic-1.8.2 sacremoses-0.0.53 scipy-1.5.4 spacy-3.2.0 spacytextblob-3.0.1 thinc-8.0.17 tokenizers-0.10.3 torch-1.9.0 tqdm-4.61.2 transformers-4.9.1 typer-0.4.2 xxhash-3.2.0\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1677758123669,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"CaZjFSDYZx7T","outputId":"8d476d59-36b0-4b78-9d4c-95898c5b646b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/dataset_difficulty-main\n"]}],"source":["%cd /content/drive/MyDrive/dataset_difficulty-main/"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7630,"status":"ok","timestamp":1677758133397,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"DjIatWUFentM","outputId":"079d0b50-20b6-4d3f-a6f6-a21afcf60d2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting numpy==1.21\n","  Downloading numpy-1.21.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m89.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.1.5 which is incompatible.\n","xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\n","torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.9.0 which is incompatible.\n","en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.21.0\n"]}],"source":["!pip install numpy==1.21"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108701,"status":"ok","timestamp":1677758246052,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"},"user_tz":-480},"id":"VOOg89-Pe5BL","outputId":"4bdb5c59-9c71-4e48-a309-61c50ba0002a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas==1.3\n","  Downloading pandas-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.6/10.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3) (2022.7.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas==1.3) (1.21.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas==1.3) (1.15.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray-einstats 0.5.1 requires scipy>=1.6, but you have scipy 1.5.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-1.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scipy==1.6\n","  Downloading scipy-1.6.0-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy==1.6) (1.21.0)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.5.4\n","    Uninstalling scipy-1.5.4:\n","      Successfully uninstalled scipy-1.5.4\n","Successfully installed scipy-1.6.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch==1.13.1\n","  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1) (4.5.0)\n","Collecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.38.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (57.4.0)\n","Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0\n","    Uninstalling torch-1.9.0:\n","      Successfully uninstalled torch-1.9.0\n","Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement spacy==3.40 (from versions: 0.31, 0.32, 0.33, 0.40, 0.51, 0.52, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.67, 0.68, 0.70, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.97, 0.98, 0.99, 0.100.0, 0.100.1, 0.100.2, 0.100.3, 0.100.4, 0.100.5, 0.100.6, 0.100.7, 0.101.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.7.2, 1.7.3, 1.7.5, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.10.0, 1.10.1, 2.0.0, 2.0.1.dev0, 2.0.1, 2.0.2.dev0, 2.0.2, 2.0.3.dev0, 2.0.3, 2.0.4.dev0, 2.0.4, 2.0.5.dev0, 2.0.5, 2.0.6.dev0, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10.dev0, 2.0.10, 2.0.11.dev0, 2.0.11, 2.0.12.dev0, 2.0.12.dev1, 2.0.12, 2.0.13.dev0, 2.0.13.dev1, 2.0.13.dev2, 2.0.13.dev4, 2.0.13, 2.0.14.dev0, 2.0.14.dev1, 2.0.15, 2.0.16.dev0, 2.0.16, 2.0.17.dev0, 2.0.17.dev1, 2.0.17, 2.0.18.dev0, 2.0.18.dev1, 2.0.18, 2.1.0, 2.1.1.dev0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.1.7.dev0, 2.1.7, 2.1.8, 2.1.9, 2.2.0.dev10, 2.2.0.dev11, 2.2.0.dev13, 2.2.0.dev15, 2.2.0.dev17, 2.2.0.dev18, 2.2.0.dev19, 2.2.0, 2.2.1, 2.2.2.dev0, 2.2.2.dev3, 2.2.2.dev4, 2.2.2, 2.2.3.dev0, 2.2.3, 2.2.4, 2.3.0.dev1, 2.3.0, 2.3.1, 2.3.2, 2.3.3.dev0, 2.3.3, 2.3.4, 2.3.5, 2.3.6, 2.3.7, 2.3.8, 2.3.9, 3.0.0, 3.0.1.dev0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.0.6, 3.0.7, 3.0.8, 3.0.9, 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.1.4, 3.1.5, 3.1.6, 3.1.7, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.2.5, 3.3.0.dev0, 3.3.0, 3.3.1, 3.3.2, 3.4.0, 3.4.1, 3.4.2, 3.4.3, 3.4.4, 3.5.0, 4.0.0.dev0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for spacy==3.40\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install pandas==1.3\n","!pip install scipy==1.6\n","!pip install torch==1.13.1\n","!pip install spacy==3.40"]},{"cell_type":"code","source":["import torch\n","print(torch.version.cuda)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQBu2JpP2kYv","executionInfo":{"status":"ok","timestamp":1677585033069,"user_tz":-480,"elapsed":862,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"}},"outputId":"1c2f86e7-f02d-42a3-e400-67c3f7aee6de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10.2\n"]}]},{"cell_type":"code","source":["!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iiXIoxol4QGx","executionInfo":{"status":"ok","timestamp":1677585437474,"user_tz":-480,"elapsed":6055,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"}},"outputId":"be81a25b-5002-478f-a997-e9b11b62de30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (57.4.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n"]}]},{"cell_type":"code","source":["!cd /content/drive/MyDrive/dataset_difficulty-main\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcgQUL_b6eO2","executionInfo":{"status":"ok","timestamp":1677636344807,"user_tz":-480,"elapsed":314,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"}},"outputId":"e18d263b-0416-4d7c-b24c-19dd89e4e557"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'Colab Notebooks'   dataset_difficulty\t      nyarumul\n"," dataset\t    dataset_difficulty-main\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cq5WyAAV4kOc","executionInfo":{"status":"ok","timestamp":1677758246052,"user_tz":-480,"elapsed":7,"user":{"displayName":"Bella Emanuel","userId":"05364725207492865613"}},"outputId":"a0ff7371-0d85-40e7-a004-c3b49bc15711"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["'$MODEL_DIR'\t\t       finetuned     requirements.txt\n"," accuracy.py\t\t       finetune.sh   results.py\n"," artefacts\t\t       main.py\t     run_glue_no_trainer.py\n"," augment.py\t\t       plot.ipynb    setup.sh\n"," data\t\t\t       PVI\t     v_info.py\n"," en_core_web_sm-3.0.0\t       __pycache__   v_info_train.py\n"," en_core_web_sm-3.0.0.tar.gz   README.md\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4B2ytkseeE35","outputId":"dbc8fc22-6790-4b20-e7b1-44bf684cbc19"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-03-02 11:57:31.854885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-03-02 11:57:36.687206: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-03-02 11:57:36.687630: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-03-02 11:57:36.687664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","03/02/2023 11:57:41 - INFO - __main__ - Distributed environment: NO\n","Num processes: 1\n","Process index: 0\n","Local process index: 0\n","Device: cpu\n","Use FP16 precision: False\n","\n","03/02/2023 11:57:42 - WARNING - datasets.builder - Using custom data configuration default-d789414d6f83b5c5\n","Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-d789414d6f83b5c5/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23...\n","Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-d789414d6f83b5c5/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23. Subsequent calls will reuse this data.\n","https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpsdzm_d2e\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 27.3kB/s]\n","storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","creating metadata file for /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","https://huggingface.co/bert-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmqpvgq35\n","Downloading: 100% 570/570 [00:00<00:00, 447kB/s]\n","storing https://huggingface.co/bert-base-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","creating metadata file for /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","https://huggingface.co/bert-base-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpm5w52mzl\n","Downloading: 100% 213k/213k [00:00<00:00, 824kB/s] \n","storing https://huggingface.co/bert-base-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","creating metadata file for /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpo5q5dqgd\n","Downloading: 100% 436k/436k [00:00<00:00, 1.27MB/s]\n","storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","creating metadata file for /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.9.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp8mr_m_q6\n","Downloading: 100% 436M/436M [00:06<00:00, 65.0MB/s]\n","storing https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","creating metadata file for /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","03/02/2023 11:58:03 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x7f9c23c04310> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","Running tokenizer on dataset: 100% 550/550 [00:57<00:00,  9.60ba/s]\n","Running tokenizer on dataset: 100% 550/550 [00:59<00:00,  9.32ba/s]\n","03/02/2023 11:59:59 - INFO - __main__ - Sample 66172 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [101, 11629, 15577, 6258, 2036, 131, 138, 1376, 2298, 4061, 1107, 170, 10791, 1113, 170, 21162, 1285, 119, 145, 24772, 14697, 3048, 9919, 6258, 131, 138, 1873, 1110, 2807, 1107, 1103, 2186, 119, 102], 'labels': 2, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","03/02/2023 11:59:59 - INFO - __main__ - Sample 267459 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [101, 11629, 15577, 6258, 2036, 131, 1960, 3287, 1576, 1170, 170, 5862, 3240, 1219, 170, 1342, 119, 145, 24772, 14697, 3048, 9919, 6258, 131, 1960, 3287, 5152, 1113, 170, 14172, 23311, 1673, 119, 102], 'labels': 2, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","03/02/2023 11:59:59 - INFO - __main__ - Sample 123646 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [101, 11629, 15577, 6258, 2036, 131, 138, 1685, 2298, 4061, 1113, 170, 2043, 1837, 1114, 1117, 1779, 1501, 119, 145, 24772, 14697, 3048, 9919, 6258, 131, 138, 2298, 1110, 2807, 1120, 1103, 4014, 1952, 5497, 6092, 2858, 9823, 119, 102], 'labels': 2, 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\n","Downloading: 2.92kB [00:00, 1.36MB/s]       \n","03/02/2023 12:00:00 - INFO - __main__ - ***** Running training *****\n","03/02/2023 12:00:00 - INFO - __main__ -   Num examples = 549367\n","03/02/2023 12:00:00 - INFO - __main__ -   Num Epochs = 2\n","03/02/2023 12:00:00 - INFO - __main__ -   Instantaneous batch size per device = 32\n","03/02/2023 12:00:00 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32\n","03/02/2023 12:00:00 - INFO - __main__ -   Gradient Accumulation steps = 1\n","03/02/2023 12:00:00 - INFO - __main__ -   Total optimization steps = 34336\n","  0% 77/34336 [1:15:33<652:57:27, 68.61s/it]"]}],"source":["!python run_glue_no_trainer.py --model_name_or_path bert-base-cased --tokenizer_name bert-base-cased --train_file /content/drive/MyDrive/dataset_difficulty-main/data/snli_train_std.csv --validation_file /content/drive/MyDrive/dataset_difficulty-main/data/snli_train_std.csv --per_device_train_batch_size 32 --per_device_eval_batch_size 32 --num_train_epochs 2 --seed 1 --output_dir /content/drive/MyDrive/dataset_difficulty-main/$MODEL_DIR/finetuned/bert-base-cased_snli_std2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TnOEsTHsgF2o"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgZb1bZpFD0/isaxq+SuZl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}